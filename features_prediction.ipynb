{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import re\n",
    "import subprocess\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import linear_model, preprocessing, utils, datasets\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "from matplotlib.pyplot import scatter\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from stats_count import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_examples_to_train = 10**10\n",
    "max_tokens_amount  = 128 # The number of tokens to which the tokenized text is truncated / padded.\n",
    "layers_of_interest = [i for i in range(12)]  # Layers for which attention matrices and features on them are \n",
    "                                             # calculated. For calculating features on all layers, leave it be\n",
    "                                             # [i for i in range(12)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = \"test_5k\"\n",
    "test_subset  = \"test_5k\" # dev/valid - for hyperparameters tuning;\n",
    "                      # test - for final testing after tuning hyperparameters on the dev set.\n",
    "input_dir = \"./small_gpt_web/\"   # Name of the directory with .csv file\n",
    "model_path = \"bert-base-uncased\"\n",
    "# You can use either standard or fine-tuned BERT. If you want to use fine-tuned BERT to your current task, save the\n",
    "# model and the tokenizer with the commands tokenizer.save_pretrained(output_dir); \n",
    "# bert_classifier.save_pretrained(output_dir) into the same directory and insert the path to it here.\n",
    "\n",
    "old_f_train_file  = input_dir + \"features/\" + train_subset + \\\n",
    "                    \"_all_heads_12_layers_s_e_v_c_b0b1_lists_array_6_thrs_MAX_LEN_128_bert-base-uncased.npy\"\n",
    "old_f_test_file   = input_dir + \"features/\" + test_subset + \\\n",
    "                    \"_all_heads_12_layers_s_e_v_c_b0b1_lists_array_6_thrs_MAX_LEN_128_bert-base-uncased.npy\"\n",
    "ripser_train_file = input_dir + \"features/\" + train_subset + \\\n",
    "                    \"_all_heads_12_layers_MAX_LEN_128_bert-base-uncased_ripser.npy\"\n",
    "ripser_test_file = input_dir + \"features/\" + test_subset + \\\n",
    "                    \"_all_heads_12_layers_MAX_LEN_128_bert-base-uncased_ripser.npy\"\n",
    "templ_train_file  = input_dir + \"features/\" + train_subset + \\\n",
    "                    \"_all_heads_12_layers_MAX_LEN_128_bert-base-uncased_template.npy\"\n",
    "templ_test_file   = input_dir + \"features/\" + test_subset + \\\n",
    "                    \"_all_heads_12_layers_MAX_LEN_128_bert-base-uncased_template.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver  = \"lbfgs\"\n",
    "is_dual = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_data = pd.read_csv(input_dir + train_subset + \".csv\")\n",
    "    test_data = pd.read_csv(input_dir + test_subset + \".csv\")\n",
    "except:\n",
    "    train_data = pd.read_csv(input_dir + train_subset + \".tsv\", delimiter=\"\\t\", header=None)\n",
    "    train_data.columns = [\"0\", \"labels\", \"2\", \"sentence\"]\n",
    "    test_data = pd.read_csv(input_dir + test_subset + \".tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"label\" in train_data.columns:\n",
    "    train_data[\"labels\"] = (train_data[\"label\"] == \"generated\").astype(int)\n",
    "    \n",
    "if \"label\" in test_data.columns:\n",
    "    test_data[\"labels\"] = (test_data[\"label\"] == \"generated\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>ended</th>\n",
       "      <th>length</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4722</td>\n",
       "      <td>259722</td>\n",
       "      <td>True</td>\n",
       "      <td>231</td>\n",
       "      <td>The Learning Co.\\n\\nDeveloped by\\n\\nThe Learni...</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2757</td>\n",
       "      <td>257813</td>\n",
       "      <td>True</td>\n",
       "      <td>563</td>\n",
       "      <td>Bush doubles down on foreign policy on Saturda...</td>\n",
       "      <td>generated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2194</td>\n",
       "      <td>257194</td>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>Here are six interesting things you need to kn...</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>817</td>\n",
       "      <td>255817</td>\n",
       "      <td>True</td>\n",
       "      <td>293</td>\n",
       "      <td>Introduction\\n\\nWe would like to thank Antec f...</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3886</td>\n",
       "      <td>258886</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>ELKRIDGE, Md.—A group called \"Muslims for Trum...</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1472</td>\n",
       "      <td>256472</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>Occasionally, we come across interesting scena...</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>326</td>\n",
       "      <td>255337</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>Providing insight not only into the memes that...</td>\n",
       "      <td>generated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>3862</td>\n",
       "      <td>258862</td>\n",
       "      <td>True</td>\n",
       "      <td>339</td>\n",
       "      <td>Each year, MONEY digs into enrollment data and...</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2862</td>\n",
       "      <td>257862</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>Grounding of the Queen Elizabeth 2 (response) ...</td>\n",
       "      <td>natural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2439</td>\n",
       "      <td>257487</td>\n",
       "      <td>True</td>\n",
       "      <td>506</td>\n",
       "      <td>Route 128\\n\\nTaxi Use\\n\\nCan 2,245 miles by 2....</td>\n",
       "      <td>generated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      id  ended  length  \\\n",
       "0           4722  259722   True     231   \n",
       "1           2757  257813   True     563   \n",
       "2           2194  257194   True      62   \n",
       "3            817  255817   True     293   \n",
       "4           3886  258886  False    1024   \n",
       "...          ...     ...    ...     ...   \n",
       "4995        1472  256472  False    1024   \n",
       "4996         326  255337  False    1024   \n",
       "4997        3862  258862   True     339   \n",
       "4998        2862  257862  False    1024   \n",
       "4999        2439  257487   True     506   \n",
       "\n",
       "                                               sentence      label  labels  \n",
       "0     The Learning Co.\\n\\nDeveloped by\\n\\nThe Learni...    natural       0  \n",
       "1     Bush doubles down on foreign policy on Saturda...  generated       1  \n",
       "2     Here are six interesting things you need to kn...    natural       0  \n",
       "3     Introduction\\n\\nWe would like to thank Antec f...    natural       0  \n",
       "4     ELKRIDGE, Md.—A group called \"Muslims for Trum...    natural       0  \n",
       "...                                                 ...        ...     ...  \n",
       "4995  Occasionally, we come across interesting scena...    natural       0  \n",
       "4996  Providing insight not only into the memes that...  generated       1  \n",
       "4997  Each year, MONEY digs into enrollment data and...    natural       0  \n",
       "4998  Grounding of the Queen Elizabeth 2 (response) ...    natural       0  \n",
       "4999  Route 128\\n\\nTaxi Use\\n\\nCan 2,245 miles by 2....  generated       1  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = list(map(int, test_data[\"labels\"]))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements for .csv files:\n",
    "\n",
    "* .csv file **train_data** must contain the column named **labels**, otherwise LogReg accuracy will not be estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 6, 5000, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_features_train = np.load(old_f_train_file, allow_pickle=True)[:,:,:,:max_examples_to_train,:]\n",
    "old_features_test  = np.load(old_f_test_file, allow_pickle=True)[:,:,:,:max_examples_to_train,:]\n",
    "old_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 5000, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ripser_train = np.load(ripser_train_file, allow_pickle=True)[:,:,:max_examples_to_train,:]\n",
    "ripser_test  = np.load(ripser_test_file, allow_pickle=True)[:,:,:max_examples_to_train,:]\n",
    "ripser_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 6, 5000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templ_train = np.load(templ_train_file, allow_pickle=True)[:,:,:,:max_examples_to_train]\n",
    "templ_test  = np.load(templ_test_file, allow_pickle=True)[:,:,:,:max_examples_to_train]\n",
    "templ_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:max_examples_to_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in range(len(train_data)):\n",
    "    features = np.concatenate((old_features_train[:,:,:,i,:].flatten(),\n",
    "                               ripser_train[:,:,i,:].flatten(),\n",
    "                               templ_train[:,:,:,i].flatten()))\n",
    "    X_train.append(features)\n",
    "y_train = train_data[\"labels\"]\n",
    "\n",
    "X_test = []\n",
    "for i in range(len(test_data)):\n",
    "    features = np.concatenate((old_features_test[:,:,:,i,:].flatten(),\n",
    "                               ripser_test[:,:,i,:].flatten(),\n",
    "                               templ_test[:,:,:,i].flatten()))\n",
    "    X_test.append(features)\n",
    "y_test = test_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:max_examples_to_train]\n",
    "train_data = train_data[:max_examples_to_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(len(train_data) == len(X_train))\n",
    "    assert(len(test_data) == len(X_test))\n",
    "except:\n",
    "    print(\"ASSERTION ERROR!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg by the feautres from all heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_Xy(X_train, y_train, X_test, classifier, verbose=False, scale=True):\n",
    "\n",
    "    if scale:\n",
    "        scaler  = preprocessing.StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"train matt:\", matthews_corrcoef(y_train, classifier.predict(X_train)))\n",
    "        print(\"train acc: \", accuracy_score(y_train, classifier.predict(X_train)))\n",
    "    \n",
    "    if scale:\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    return classifier.predict(X_test), \\\n",
    "           matthews_corrcoef(y_train, classifier.predict(X_train)), \\\n",
    "           accuracy_score(y_train, classifier.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression(solver=solver)\n",
    "\n",
    "# The classifier with concrete hyperparameters values, which you should insert here.\n",
    "# For grid search of hyperparameters - see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search of hyperparameters. Use it on the dev/vaild set!\n",
    "\n",
    "(**Reminder**: Don't tune hyperparameters on the test set, to not overfit hyperparameters. Tune hyperparameters on the dev/valid set, and then use the best ones on the test set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2] [1, 2, 3, 5, 10, 25, 50, 100, 500, 1000, 2000]\n"
     ]
    }
   ],
   "source": [
    "C_range = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]\n",
    "max_iter_range = [1, 2, 3, 5, 10, 25, 50, 100, 500, 1000, 2000]\n",
    "\n",
    "print(C_range, max_iter_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274a0bd327d24969b9b4a8d301e851f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matt_scores = dict()\n",
    "acc_scores  = dict()\n",
    "matt_scores_train = dict()\n",
    "acc_scores_train  = dict()\n",
    "results     = dict()\n",
    "\n",
    "for C in tqdm(C_range):\n",
    "    for max_iter in max_iter_range:\n",
    "        classifier = linear_model.LogisticRegression(penalty='l2', C=C, max_iter=max_iter, dual=is_dual,\n",
    "                                                     solver=solver)\n",
    "\n",
    "        result, train_matt, train_acc = pred_by_Xy(X_train, y_train, X_test, classifier)\n",
    "        results[(C, max_iter)] = result\n",
    "\n",
    "        matt_scores_train[(C, max_iter)] = matthews_corrcoef(result, y_test)\n",
    "        acc_scores_train[(C, max_iter)]  = accuracy_score(result, y_test)\n",
    "\n",
    "        try:\n",
    "            matt_scores[(C, max_iter)] = matthews_corrcoef(result, y_test)\n",
    "            acc_scores[(C, max_iter)]  = accuracy_score(result, y_test)\n",
    "            #print(\"test matt: \", matthews_corrcoef(result, y_test))\n",
    "            #print(\"test acc:  \", accuracy_score(result, y_test))\n",
    "        except:\n",
    "            #print(\"Not labeled\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prints the list of hyperparameters and corresponding matthews corcoef / accuracy of LogReg, trained with these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3313f56acb430a95e745cb2e57a893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 1 , matt: 0.4654078090461891\n",
      "0.0001 1 , acc : 0.73\n",
      "\n",
      "0.0001 2 , matt: 0.5321587494013718\n",
      "0.0001 2 , acc : 0.7656\n",
      "\n",
      "0.0001 3 , matt: 0.5521643352990641\n",
      "0.0001 3 , acc : 0.7758\n",
      "\n",
      "0.0001 5 , matt: 0.665980507012388\n",
      "0.0001 5 , acc : 0.8326\n",
      "\n",
      "0.0001 10 , matt: 0.7404967810889473\n",
      "0.0001 10 , acc : 0.8698\n",
      "\n",
      "0.0001 25 , matt: 0.748364860532234\n",
      "0.0001 25 , acc : 0.8738\n",
      "\n",
      "0.0001 50 , matt: 0.7471922892682197\n",
      "0.0001 50 , acc : 0.8734\n",
      "\n",
      "0.0001 100 , matt: 0.7471922892682197\n",
      "0.0001 100 , acc : 0.8734\n",
      "\n",
      "0.0001 500 , matt: 0.7471922892682197\n",
      "0.0001 500 , acc : 0.8734\n",
      "\n",
      "0.0001 1000 , matt: 0.7471922892682197\n",
      "0.0001 1000 , acc : 0.8734\n",
      "\n",
      "0.0001 2000 , matt: 0.7471922892682197\n",
      "0.0001 2000 , acc : 0.8734\n",
      "\n",
      "0.0005 1 , matt: 0.4654078090461891\n",
      "0.0005 1 , acc : 0.73\n",
      "\n",
      "0.0005 2 , matt: 0.5341495362847585\n",
      "0.0005 2 , acc : 0.7666\n",
      "\n",
      "0.0005 3 , matt: 0.552184520597935\n",
      "0.0005 3 , acc : 0.7758\n",
      "\n",
      "0.0005 5 , matt: 0.686726941860376\n",
      "0.0005 5 , acc : 0.843\n",
      "\n",
      "0.0005 10 , matt: 0.7689772836772955\n",
      "0.0005 10 , acc : 0.884\n",
      "\n",
      "0.0005 25 , matt: 0.8351962442781764\n",
      "0.0005 25 , acc : 0.9174\n",
      "\n",
      "0.0005 50 , matt: 0.8362098146407478\n",
      "0.0005 50 , acc : 0.918\n",
      "\n",
      "0.0005 100 , matt: 0.8361950903486696\n",
      "0.0005 100 , acc : 0.918\n",
      "\n",
      "0.0005 500 , matt: 0.8361950903486696\n",
      "0.0005 500 , acc : 0.918\n",
      "\n",
      "0.0005 1000 , matt: 0.8361950903486696\n",
      "0.0005 1000 , acc : 0.918\n",
      "\n",
      "0.0005 2000 , matt: 0.8361950903486696\n",
      "0.0005 2000 , acc : 0.918\n",
      "\n",
      "0.001 1 , matt: 0.4654078090461891\n",
      "0.001 1 , acc : 0.73\n",
      "\n",
      "0.001 2 , matt: 0.5341495362847585\n",
      "0.001 2 , acc : 0.7666\n",
      "\n",
      "0.001 3 , matt: 0.552184520597935\n",
      "0.001 3 , acc : 0.7758\n",
      "\n",
      "0.001 5 , matt: 0.6899303328428151\n",
      "0.001 5 , acc : 0.8446\n",
      "\n",
      "0.001 10 , matt: 0.7728323868731362\n",
      "0.001 10 , acc : 0.886\n",
      "\n",
      "0.001 25 , matt: 0.8725676188879004\n",
      "0.001 25 , acc : 0.9362\n",
      "\n",
      "0.001 50 , matt: 0.8777485978610337\n",
      "0.001 50 , acc : 0.9388\n",
      "\n",
      "0.001 100 , matt: 0.8768909207642416\n",
      "0.001 100 , acc : 0.9384\n",
      "\n",
      "0.001 500 , matt: 0.8768909207642416\n",
      "0.001 500 , acc : 0.9384\n",
      "\n",
      "0.001 1000 , matt: 0.8768909207642416\n",
      "0.001 1000 , acc : 0.9384\n",
      "\n",
      "0.001 2000 , matt: 0.8768909207642416\n",
      "0.001 2000 , acc : 0.9384\n",
      "\n",
      "0.005 1 , matt: 0.4654078090461891\n",
      "0.005 1 , acc : 0.73\n",
      "\n",
      "0.005 2 , matt: 0.5341495362847585\n",
      "0.005 2 , acc : 0.7666\n",
      "\n",
      "0.005 3 , matt: 0.552184520597935\n",
      "0.005 3 , acc : 0.7758\n",
      "\n",
      "0.005 5 , matt: 0.6907830180497521\n",
      "0.005 5 , acc : 0.845\n",
      "\n",
      "0.005 10 , matt: 0.7742446877435\n",
      "0.005 10 , acc : 0.8868\n",
      "\n",
      "0.005 25 , matt: 0.9284541490250027\n",
      "0.005 25 , acc : 0.9642\n",
      "\n",
      "0.005 50 , matt: 0.9616003077121478\n",
      "0.005 50 , acc : 0.9808\n",
      "\n",
      "0.005 100 , matt: 0.9628037741981923\n",
      "0.005 100 , acc : 0.9814\n",
      "\n",
      "0.005 500 , matt: 0.9620037710621738\n",
      "0.005 500 , acc : 0.981\n",
      "\n",
      "0.005 1000 , matt: 0.9620037710621738\n",
      "0.005 1000 , acc : 0.981\n",
      "\n",
      "0.005 2000 , matt: 0.9620037710621738\n",
      "0.005 2000 , acc : 0.981\n",
      "\n",
      "0.01 1 , matt: 0.4654078090461891\n",
      "0.01 1 , acc : 0.73\n",
      "\n",
      "0.01 2 , matt: 0.5341495362847585\n",
      "0.01 2 , acc : 0.7666\n",
      "\n",
      "0.01 3 , matt: 0.552184520597935\n",
      "0.01 3 , acc : 0.7758\n",
      "\n",
      "0.01 5 , matt: 0.6911967177929831\n",
      "0.01 5 , acc : 0.8452\n",
      "\n",
      "0.01 10 , matt: 0.7762591064460279\n",
      "0.01 10 , acc : 0.8878\n",
      "\n",
      "0.01 25 , matt: 0.9444091419247409\n",
      "0.01 25 , acc : 0.9722\n",
      "\n",
      "0.01 50 , matt: 0.9848012605464204\n",
      "0.01 50 , acc : 0.9924\n",
      "\n",
      "0.01 100 , matt: 0.9908000792640095\n",
      "0.01 100 , acc : 0.9954\n",
      "\n",
      "0.01 500 , matt: 0.9904003169281522\n",
      "0.01 500 , acc : 0.9952\n",
      "\n",
      "0.01 1000 , matt: 0.9904003169281522\n",
      "0.01 1000 , acc : 0.9952\n",
      "\n",
      "0.01 2000 , matt: 0.9904003169281522\n",
      "0.01 2000 , acc : 0.9952\n",
      "\n",
      "0.05 1 , matt: 0.4654078090461891\n",
      "0.05 1 , acc : 0.73\n",
      "\n",
      "0.05 2 , matt: 0.5341495362847585\n",
      "0.05 2 , acc : 0.7666\n",
      "\n",
      "0.05 3 , matt: 0.552184520597935\n",
      "0.05 3 , acc : 0.7758\n",
      "\n",
      "0.05 5 , matt: 0.6915839258967662\n",
      "0.05 5 , acc : 0.8454\n",
      "\n",
      "0.05 10 , matt: 0.7786356885049391\n",
      "0.05 10 , acc : 0.889\n",
      "\n",
      "0.05 25 , matt: 0.9572019144057432\n",
      "0.05 25 , acc : 0.9786\n",
      "\n",
      "0.05 50 , matt: 1.0\n",
      "0.05 50 , acc : 1.0\n",
      "\n",
      "0.05 100 , matt: 1.0\n",
      "0.05 100 , acc : 1.0\n",
      "\n",
      "0.05 500 , matt: 1.0\n",
      "0.05 500 , acc : 1.0\n",
      "\n",
      "0.05 1000 , matt: 1.0\n",
      "0.05 1000 , acc : 1.0\n",
      "\n",
      "0.05 2000 , matt: 1.0\n",
      "0.05 2000 , acc : 1.0\n",
      "\n",
      "0.1 1 , matt: 0.4654078090461891\n",
      "0.1 1 , acc : 0.73\n",
      "\n",
      "0.1 2 , matt: 0.5341495362847585\n",
      "0.1 2 , acc : 0.7666\n",
      "\n",
      "0.1 3 , matt: 0.552184520597935\n",
      "0.1 3 , acc : 0.7758\n",
      "\n",
      "0.1 5 , matt: 0.6915839258967662\n",
      "0.1 5 , acc : 0.8454\n",
      "\n",
      "0.1 10 , matt: 0.7786356885049391\n",
      "0.1 10 , acc : 0.889\n",
      "\n",
      "0.1 25 , matt: 0.9584012267543555\n",
      "0.1 25 , acc : 0.9792\n",
      "\n",
      "0.1 50 , matt: 1.0\n",
      "0.1 50 , acc : 1.0\n",
      "\n",
      "0.1 100 , matt: 1.0\n",
      "0.1 100 , acc : 1.0\n",
      "\n",
      "0.1 500 , matt: 1.0\n",
      "0.1 500 , acc : 1.0\n",
      "\n",
      "0.1 1000 , matt: 1.0\n",
      "0.1 1000 , acc : 1.0\n",
      "\n",
      "0.1 2000 , matt: 1.0\n",
      "0.1 2000 , acc : 1.0\n",
      "\n",
      "0.5 1 , matt: 0.4654078090461891\n",
      "0.5 1 , acc : 0.73\n",
      "\n",
      "0.5 2 , matt: 0.5341495362847585\n",
      "0.5 2 , acc : 0.7666\n",
      "\n",
      "0.5 3 , matt: 0.552184520597935\n",
      "0.5 3 , acc : 0.7758\n",
      "\n",
      "0.5 5 , matt: 0.6915839258967662\n",
      "0.5 5 , acc : 0.8454\n",
      "\n",
      "0.5 10 , matt: 0.7786356885049391\n",
      "0.5 10 , acc : 0.889\n",
      "\n",
      "0.5 25 , matt: 0.964409335527552\n",
      "0.5 25 , acc : 0.9822\n",
      "\n",
      "0.5 50 , matt: 1.0\n",
      "0.5 50 , acc : 1.0\n",
      "\n",
      "0.5 100 , matt: 1.0\n",
      "0.5 100 , acc : 1.0\n",
      "\n",
      "0.5 500 , matt: 1.0\n",
      "0.5 500 , acc : 1.0\n",
      "\n",
      "0.5 1000 , matt: 1.0\n",
      "0.5 1000 , acc : 1.0\n",
      "\n",
      "0.5 2000 , matt: 1.0\n",
      "0.5 2000 , acc : 1.0\n",
      "\n",
      "1 1 , matt: 0.4654078090461891\n",
      "1 1 , acc : 0.73\n",
      "\n",
      "1 2 , matt: 0.5341495362847585\n",
      "1 2 , acc : 0.7666\n",
      "\n",
      "1 3 , matt: 0.552184520597935\n",
      "1 3 , acc : 0.7758\n",
      "\n",
      "1 5 , matt: 0.6915839258967662\n",
      "1 5 , acc : 0.8454\n",
      "\n",
      "1 10 , matt: 0.7786356885049391\n",
      "1 10 , acc : 0.889\n",
      "\n",
      "1 25 , matt: 0.9536003051521466\n",
      "1 25 , acc : 0.9768\n",
      "\n",
      "1 50 , matt: 1.0\n",
      "1 50 , acc : 1.0\n",
      "\n",
      "1 100 , matt: 1.0\n",
      "1 100 , acc : 1.0\n",
      "\n",
      "1 500 , matt: 1.0\n",
      "1 500 , acc : 1.0\n",
      "\n",
      "1 1000 , matt: 1.0\n",
      "1 1000 , acc : 1.0\n",
      "\n",
      "1 2000 , matt: 1.0\n",
      "1 2000 , acc : 1.0\n",
      "\n",
      "2 1 , matt: 0.4654078090461891\n",
      "2 1 , acc : 0.73\n",
      "\n",
      "2 2 , matt: 0.5341495362847585\n",
      "2 2 , acc : 0.7666\n",
      "\n",
      "2 3 , matt: 0.552184520597935\n",
      "2 3 , acc : 0.7758\n",
      "\n",
      "2 5 , matt: 0.6915839258967662\n",
      "2 5 , acc : 0.8454\n",
      "\n",
      "2 10 , matt: 0.7786356885049391\n",
      "2 10 , acc : 0.889\n",
      "\n",
      "2 25 , matt: 0.9520003046401463\n",
      "2 25 , acc : 0.976\n",
      "\n",
      "2 50 , matt: 1.0\n",
      "2 50 , acc : 1.0\n",
      "\n",
      "2 100 , matt: 1.0\n",
      "2 100 , acc : 1.0\n",
      "\n",
      "2 500 , matt: 1.0\n",
      "2 500 , acc : 1.0\n",
      "\n",
      "2 1000 , matt: 1.0\n",
      "2 1000 , acc : 1.0\n",
      "\n",
      "2 2000 , matt: 1.0\n",
      "2 2000 , acc : 1.0\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "The best Acc score:\n",
      "\n",
      "1.0\n",
      "\n",
      "The best Matthew score:\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for C in tqdm(C_range):\n",
    "        for max_iter in max_iter_range:\n",
    "            print(C, max_iter, \", matt:\", matt_scores[(C, max_iter)])\n",
    "            print(C, max_iter, \", acc :\", acc_scores[(C, max_iter)])\n",
    "            print()\n",
    "    print(\"---\")\n",
    "    print()\n",
    "    print(\"The best Acc score:\")\n",
    "    print()\n",
    "    print(max(acc_scores.values()))\n",
    "    print()\n",
    "    print(\"The best Matthew score:\")\n",
    "    print()\n",
    "    print(max(matt_scores.values()))\n",
    "\n",
    "except:\n",
    "    print(\"Data is not labeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
